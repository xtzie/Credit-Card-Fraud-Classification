{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T06:03:30.826908Z",
     "start_time": "2020-03-02T06:03:29.936453Z"
    }
   },
   "outputs": [],
   "source": [
    "import psycopg2 as pg\n",
    "import pandas.io.sql as pd_sql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "connection_args = {\n",
    "    'host': 'localhost',  # We are connecting to our _local_ version of psql\n",
    "    'dbname': 'ccfraud',    # DB that we are connecting to\n",
    "    'port': 5432          # port for psql\n",
    "}\n",
    "\n",
    "connection = pg.connect(**connection_args)\n",
    "\n",
    "query = 'SELECT * FROM ccdata'\n",
    "\n",
    "df = pd_sql.read_sql(query, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>...</th>\n",
       "      <th>v21</th>\n",
       "      <th>v22</th>\n",
       "      <th>v23</th>\n",
       "      <th>v24</th>\n",
       "      <th>v25</th>\n",
       "      <th>v26</th>\n",
       "      <th>v27</th>\n",
       "      <th>v28</th>\n",
       "      <th>amount</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359810</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536350</td>\n",
       "      <td>1.378160</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191860</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358350</td>\n",
       "      <td>-1.340160</td>\n",
       "      <td>1.773210</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800500</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792990</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247200</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387020</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175580</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158230</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548720</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095922</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798279</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881100</td>\n",
       "      <td>10.071800</td>\n",
       "      <td>-9.834780</td>\n",
       "      <td>-2.066660</td>\n",
       "      <td>-5.364470</td>\n",
       "      <td>-2.606840</td>\n",
       "      <td>-4.918220</td>\n",
       "      <td>7.305330</td>\n",
       "      <td>1.914430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436810</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058420</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016230</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068473</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919560</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630520</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577010</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            time         v1         v2        v3        v4        v5  \\\n",
       "0            0.0  -1.359810  -0.072781  2.536350  1.378160 -0.338321   \n",
       "1            0.0   1.191860   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358350  -1.340160  1.773210  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792990 -0.863291 -0.010309   \n",
       "4            2.0  -1.158230   0.877737  1.548720  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881100  10.071800 -9.834780 -2.066660 -5.364470   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919560  -0.301254 -3.249640 -0.557828  2.630520   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              v6        v7        v8        v9  ...       v21       v22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800500  0.791461  0.247676 -1.514650  ...  0.247998  0.771679   \n",
       "3       1.247200  0.237609  0.377436 -1.387020  ... -0.108300  0.005274   \n",
       "4       0.095922  0.592941 -0.270533  0.817739  ... -0.009431  0.798279   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606840 -4.918220  7.305330  1.914430  ...  0.213454  0.111864   \n",
       "284803  1.058420  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577010 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             v23       v24       v25       v26       v27       v28  amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175580  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436810  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016230 -0.606624 -0.395255  0.068473 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T06:03:39.310312Z",
     "start_time": "2020-03-02T06:03:39.296397Z"
    }
   },
   "outputs": [],
   "source": [
    "# df.isnull().sum()\n",
    "#gives view per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "# profile = ProfileReport(df, minimal=True)\n",
    "# profile\n",
    "#kaggle highlighted a power transform was applied to the 28 variables, so perhaps transformation is only required\n",
    "#on the remaining 'Time' and 'Amount' columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remember to rebind to the df\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df['scaled_amount'] = StandardScaler().fit_transform(df['Amount'].values.reshape(-1, 1))\n",
    "df['scaled_time'] = StandardScaler().fit_transform(df['Time'].values.reshape(-1, 1))\n",
    "\n",
    "#correct error message\n",
    "#Reshape your data either using array.reshape(-1, 1) \n",
    "#if your data has a single feature or array.reshape(1, -1) if it contains a single sample\n",
    "#df.values returns whatever slice or dataframe as an array, so rmb to plug that in so that\n",
    "#data is in the right format for fit_transform to work\n",
    "\n",
    "df.drop(['Amount', 'Time'], axis = 1, inplace = True)\n",
    "#syntax  --- df.drop([row or column, row or column, row or column], axis = 0 or 1, inplace = True)\n",
    "#axis = 1 means will drop columns, axis = 0 means will drop rows\n",
    "#there is no need to rebind df = df.drop\n",
    "# as you have passed inplace = True\n",
    "#which drops it permanently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>-1.996583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>-1.996583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>-1.996562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>-1.996562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>-1.996541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>4.356170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.350151</td>\n",
       "      <td>1.641931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>-0.975926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.254117</td>\n",
       "      <td>1.641952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>-0.484782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.081839</td>\n",
       "      <td>1.641974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>-0.399126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.313249</td>\n",
       "      <td>1.641974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>-0.915427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>0</td>\n",
       "      <td>0.514355</td>\n",
       "      <td>1.642058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               V1         V2        V3        V4        V5        V6  \\\n",
       "0       -1.359807  -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1        1.191857   0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2       -1.358354  -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3       -0.966272  -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4       -1.158233   0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "...           ...        ...       ...       ...       ...       ...   \n",
       "284802 -11.881118  10.071785 -9.834783 -2.066656 -5.364473 -2.606837   \n",
       "284803  -0.732789  -0.055080  2.035030 -0.738589  0.868229  1.058415   \n",
       "284804   1.919565  -0.301254 -3.249640 -0.557828  2.630515  3.031260   \n",
       "284805  -0.240440   0.530483  0.702510  0.689799 -0.377961  0.623708   \n",
       "284806  -0.533413  -0.189733  0.703337 -0.506271 -0.012546 -0.649617   \n",
       "\n",
       "              V7        V8        V9       V10  ...       V22       V23  \\\n",
       "0       0.239599  0.098698  0.363787  0.090794  ...  0.277838 -0.110474   \n",
       "1      -0.078803  0.085102 -0.255425 -0.166974  ... -0.638672  0.101288   \n",
       "2       0.791461  0.247676 -1.514654  0.207643  ...  0.771679  0.909412   \n",
       "3       0.237609  0.377436 -1.387024 -0.054952  ...  0.005274 -0.190321   \n",
       "4       0.592941 -0.270533  0.817739  0.753074  ...  0.798278 -0.137458   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -4.918215  7.305334  1.914428  4.356170  ...  0.111864  1.014480   \n",
       "284803  0.024330  0.294869  0.584800 -0.975926  ...  0.924384  0.012463   \n",
       "284804 -0.296827  0.708417  0.432454 -0.484782  ...  0.578229 -0.037501   \n",
       "284805 -0.686180  0.679145  0.392087 -0.399126  ...  0.800049 -0.163298   \n",
       "284806  1.577006 -0.414650  0.486180 -0.915427  ...  0.643078  0.376777   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Class  \\\n",
       "0       0.066928  0.128539 -0.189115  0.133558 -0.021053      0   \n",
       "1      -0.339846  0.167170  0.125895 -0.008983  0.014724      0   \n",
       "2      -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0   \n",
       "3      -1.175575  0.647376 -0.221929  0.062723  0.061458      0   \n",
       "4       0.141267 -0.206010  0.502292  0.219422  0.215153      0   \n",
       "...          ...       ...       ...       ...       ...    ...   \n",
       "284802 -0.509348  1.436807  0.250034  0.943651  0.823731      0   \n",
       "284803 -1.016226 -0.606624 -0.395255  0.068472 -0.053527      0   \n",
       "284804  0.640134  0.265745 -0.087371  0.004455 -0.026561      0   \n",
       "284805  0.123205 -0.569159  0.546668  0.108821  0.104533      0   \n",
       "284806  0.008797 -0.473649 -0.818267 -0.002415  0.013649      0   \n",
       "\n",
       "        scaled_amount  scaled_time  \n",
       "0            0.244964    -1.996583  \n",
       "1           -0.342475    -1.996583  \n",
       "2            1.160686    -1.996562  \n",
       "3            0.140534    -1.996562  \n",
       "4           -0.073403    -1.996541  \n",
       "...               ...          ...  \n",
       "284802      -0.350151     1.641931  \n",
       "284803      -0.254117     1.641952  \n",
       "284804      -0.081839     1.641974  \n",
       "284805      -0.313249     1.641974  \n",
       "284806       0.514355     1.642058  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001727485630620034\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgcAAAF9CAYAAACQ8MsBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deVxU9f7H8dewjLiAiCzXhdxIMENcyJ20cCnzejVRcGvTzI1rpZmaueSCaWaFlhplZpn+NO2aGdiiXkvEhTTNXMMyFxhUBFlkm98f/pifJ9DQBBLfz8fDh8x3zvnO50zhvOf7Ped8TVar1YqIiIjI/7Er6wJERETk70XhQERERAwUDkRERMRA4UBEREQMFA5ERETEQOFAREREDBQOROSWGjRoEL6+vvz++++3tF9fX18efPBBAH7//Xd8fX0ZNGjQLX2NuLg4fH19GT9+/C3tV+R241DWBYjItf3+++8EBwfbHtvb21O9enUCAwN58sknadKkSbH7WrJkCStXruTbb7+9qVp8fX1tP9vZ2eHq6kpAQACDBg2iXbt2tucGDx5Mjx49qFat2i2ta8aMGVSuXPmmar+Wffv20bdvX7755htq165NvXr1mDFjBnXr1r2lryNyu1E4ELkNVK1alRdeeIHLly9z8OBB/vOf/xATE8PcuXN55JFHitXH1q1bb0ktr7zyCnl5efzyyy98+umnbN68mRdeeIEhQ4YA0LFjxxvqr7h19enT50ZL/VNbtmwxPPb09CyR1xG53WhaQeQ24OTkRJ8+fRg4cCCzZs0iKiqKvLw8pkyZQlpaGgCHDh3iqaee4r777qNVq1aMHTuW1NRU4Mq3/t27d3Pq1Cl8fX2Ji4sjOzubmTNn0rFjR5o2bcqjjz7K7t27/7SW3r17079/fyZNmsTq1asxm83Mnz+f3377DSg8rbB//34GDRpEYGAgLVq0YMiQIfzyyy/XrCsyMhJfX1+WLFlC7969eeqpp2zbFkwrXG3ZsmW0b9+eZs2aMXXqVPLy8gAYP368rc8CDz74IL6+vvz6668MGjSIt99+G4Dg4GAiIyOLnFbYv38/YWFhNGnShObNm/PMM89w7NixQn3+/PPP9O7dm2bNmjF48GDOnTtXzP+6In8/Cgcit6E2bdrQsmVL0tLS+P7778nLy+OZZ55hx44dPPnkk3Tt2pXPP/+c119/HbgyJA/g6urKjBkzqFevHgsWLODDDz+kUaNGPPvss5w8eZKRI0eSmZlZ7Dp8fHzo3r07ubm5fPXVV4Wez8/PZ/jw4SQkJDBixAiGDRvGjz/+yNChQ8nPzy+yrgJLly6lWbNmhIaGXvP1jx49yrfffsuTTz6Ji4sLn3zyCevXry9W7YMHD7ZNH4wZM6bI4HH8+HH69evH8ePHGT58OH369GHbtm088cQThd6nSZMm0bVrV+655x6+++473nzzzWLVIfJ3pGkFkdvU3Xffzc6dO/ntt9/Iy8vjzTffxNHRkRo1apCVlcWqVatsIwF9+vRh0qRJVK5c2TZs/q9//YsHH3yQGjVqYGdnx65du/j66685duwY/v7+xa7Dx8cHwDZycLVLly5hsVho0qQJISEhuLi4EBQURF5eHlartci6Cvj6+jJp0qTrvvbly5dZuHAhVapUoUaNGjz33HN8+eWX9OrV60/r7tixI++99x4nTpygW7du1K5d2zDKABAVFUVOTg5Tpkyx1ZeSksJnn33Ghg0bDDUPHDiQXr160bVrV7p06cLevXv/tAaRvyuFA5HbVG5uLnDlJEWz2cy3337L8uXLycjIsG1z9c9/ZLFYmDp1KgkJCYb26+1TlIJhfHt7+0LPubi48MADD7B582batGlDo0aNaNu2LQMGDChy+6v5+fn96WvffffdVKlSBYCGDRsC3NKrJA4fPgxgCEv33HMPn332mWFqAeDee+8FoHbt2sCVYCRyu9K0gsht6siRIwDUr1+frVu3snjxYqpXr868efNYsmTJn+7//PPPk5CQwHPPPceSJUto3br1TdVR8AFav379Ip9fuHAh8+fPp3v37pw/f57FixfTt2/fP/3wrFChwp++dkFAgitTGAAmk8mwzdULz2ZnZ/9pn9fa989ex2w2A0WHJJHbjcKByG3ov//9Lz/88APu7u60adOGo0ePAtCpUye6d++Om5sbUPjDreBb/vnz5zl37hyurq4MGzaMDh06cP78+SL3uZ7Dhw8THR2N2WymS5cuhZ6/dOkSO3fuxN/fn1dffZVvv/2WRx99lLNnz/LTTz8VqutGJSQk2EJGQUjx9vYGsI0onD17FoDExMRrniRY8IH/RwWjEfv377e1/fjjj4bnRMojTSuI3AaysrJYvXo1eXl5HDp0iDVr1uDg4MC0adNwcnLirrvuAuCbb77By8uLtWvXUq9ePU6ePMnHH3/MgAEDcHFxITExkQULFtCtWzdcXFxISUkhMjKS48eP277xrl69mlq1atk+ZP/o008/xWQykZCQwKpVq8jNzWXy5Ml4enoW2vbs2bM89dRT+Pj40LdvX/Lz84mPj6dChQq2kwH/WNeNsLe3Jzw8nPbt27N06VIAevToAWC7B8Tbb79NTk4On3/+Oa6urrYQVPDacGV0o2fPntjZGb8vDR06lC+++IK5c+dy/vx5zp49y5dffsldd91F9+7db6hWkduJRg5EbgMXL15k0qRJTJkyhS+++IL27duzYsUKOnXqBFwZMejduzfnzp3jo48+YvTo0YwaNQqz2czKlSsBGDZsGBUrVuTDDz8kMTGRiIgI/vGPf7B06VKqVavGkiVLqFu3Lt9++y1nzpy5Zi2TJ0/m5ZdfZuXKlfj7+/Puu+8yYMCAIrf18fHhrbfewtHRkXnz5vHmm29SrVo1Fi1ahJeXV5F1FUfB6Ebz5s257777WLRoEVlZWfz73/+2BYxu3boRGhrKhQsXWLhwISEhIYarIeDKZZceHh7ExMTYRgSu1qBBA1asWEHdunVZsGABn3/+OQ8//DCffPKJbRpBpDwyWW9kDFFERETKPY0ciIiIiIHCgYiIiBgoHIiIiIiBwoGIiIgYKByI/EVjx47F19eXbdu2lXUpfysF78vatWtLpP+CRZIiIyMBWLt2bYm+3q3Ur1+/QotC3axz587RvHlzOnfufMM3eRK5FoUDkb/g559/ZsOGDbRt25agoCDbioIBAQG2m+8U8PX1ZdCgQSVaT8GKiEX9uR0+NH/99VfbypIPPPAAc+fOveYNim5UweqJRf25FR/SJS0nJ4c333yTxo0b4+vra2uvXr06Tz/9NL/99pvtslWRv0o3QRL5C1asWIHVai10nX9WVhbz58/n1VdfLZO6nnzySRo0aGBoa968eZnUUlxWq5VRo0aRkJDA8OHD+fnnn4mKisLDw4Mnnnjilr3O888/b7uDZIE/3v/g7yYlJYUnnniCEydOYG9vb7htNEBoaCgLFy5kxYoVPPbYY2VUpZQnGjkQuUlWq5WYmBiqVKlCx44dDc/94x//YP369Rw8ePCa+//6668MHjyYZs2a0bRpUwYOHEh8fLzt+YJRgLi4OB5//HGaNm1KaGgoJ06c+NPa7r//fvr06WP4U7duXX7//Xd8fX0JDQ1l/vz5BAQEcObMGVJSUpgwYQLt27enWbNmDBo0yLZ2A1wZ9bh6SeOCIf1+/frZ2mJiYrj//vtp1qwZL730UqFv/EXtc7W9e/dy5MgRHn30UUaOHMnrr79OpUqVWLNmzZ8e74146KGHCr03np6etvqef/55xo8fT0BAAACnTp0iPDyc1q1b06JFC4YNG2a7SVTB+3n1iFDB9MbYsWNtbR9//DGtW7cmMDCQ+fPnF6qpqH2ulpSUhIuLC+vXr8fd3b3Q825ubrRu3ZqEhAQOHTr0l94fEVA4ELlpCQkJXLx4EX9/fxwcjINwgwcPBrjmyMH58+cJCQlh586dDBo0iKeeeor9+/fz1FNPFbpL4CuvvMJ9991H27Zt2bt3L9OnT//LtZ84cYKdO3cyduxYqlSpwvTp01m7di1BQUEMHz6cH374gWeffbbY/Z0+fZrnn3+elJQUhg8fTn5+Pt9+++0N1VTwoVYw4mE2m6lTpw7Hjx/n8uXLN9TXX7F9+3bOnz9v+6AeM2YMmzZtolevXgwcOJDNmzczefLkYvcXHx/PK6+8gtVqJTw8nMOHD/Pzzz/fUE316tVj2bJltttkF6UgzFy9DoTIzdK0gshNOnnyJIBtjYCr+fr60qNHDz777DO2bNlSaGRhxYoVpKamMmzYMJ577jlbe8HQ8NVtDz/8MKNGjSIjI4OWLVuyd+/eP63t4sWLWCwWQ1u1atUMz7/++uvUqFEDgCFDhjBo0CBq166N1WolOjqan376ifPnzxcagi/Kxo0byc3NJSQkhKFDh2K1WomPjzeMcrRo0YJdu3Zdc9XCixcvAlC5cmVbW+XKlcnPzyclJcV2u+W/6sKFC1SqVMnQdvW38ezsbN566y2cnJwAmDBhAgB33XUXubm5rF69mt27dxf79T7//HPgSmB8/PHH6du3L+3btzds0717dzp16oSjo2ORfVyr/WoFUyO//fZbsWsTuRaFA5GblJaWBoCzs3ORzz/77LNER0czd+5cgoKCDM8VrCDo7+9va7vnnnsAOH78uGHbe++9F4BKlSpRvXp124mOFy9eJDMzE7iyAJGHh4fhtf/os88+s9VatWpVWzCAK6Mgc+bMKbSmQkZGRrHCwenTp4EraynAleWM/fz8DOHAwcHBttBRUYq6k3tB2x+XR/4rQkNDC7Xt2rXL9nPdunVtwQCurMK4cOFCLly4cFOv98f3pmLFitSrV8/wDd9sNv/ltRoK3tvU1NS/1I8IKByI/GXX+uCqUaMGjz/+OIsXL2b16tWG7Yr6ICyYo/9jf1d/aFz9rTsiIoJ169YBUKtWLcMw/pgxY/Dz8zP04+3tTUpKCgAVKlSwtV+8eJFx48ZhMpmYPHky3t7ezJkzx7YMdFE15+TkFHnMV2+TlZVV5DbXUjCykZ6ebmtLT0/Hzs4OV1fXG+rrembNmmUIUoBhJOHq9+bo0aPMmDEDV1dXZs+eTfXq1Rk3blyhoFDS701xaJkcuZUUDkRuUsG38IIRhKIMHTqU1atXExkZafjQadiwIV999RX79++3raxYsCpgw4YNi/X6Tz75pG0Fwqu/6cKV0Ya2bdsW2qcgHFzt119/JScnh8aNGzNgwAAuX75sm5Io+MCpXLky58+fJzs7G7PZXOhEy5o1awLYAkXB0tJXy8vLIysrC3t7+0L1AjRu3BiAY8eOAVc+QH/99VcaNmx4S1dADAwMpE6dOsXatqCWli1b0qtXL5KTk23fzK1WK1WqVAEwjLj89NNPhj6ufm+Cg4NJTU0tNPSfm5vL5cuXcXR0vOljLfj/8HqjMyLFpXAgcpO8vb2BK0Py11KlShVGjhxZ6CTCgQMH8tFHH/H+++9jZ2dHTk4OH3zwAVWrVr3m8sd/VHCN/l9Vs2ZNHBwcOHr0KO+++y6xsbHUqFGDlJQUli1bxogRIwgICGD79u1MnDiRJk2a2EYsCnTt2pV58+axbt06vLy8OHLkiG3Ko8Du3bt57LHHaN68OZ988kmhOvz9/WncuDHr1q2jRo0a/Pjjj2RmZl7z6obSUHAC4K5du1i6dCkbN27Ex8eHw4cPs3DhQoYOHUrdunU5ceIEs2bNws3Nje+++87Qx8MPP8yKFSuIiorCzs6O7du3U6FCBcNJluvXr2fChAn885//5LXXXitUx8mTJ21XbRSEk4KrHkJCQvD29rZN4VzvpEWR4tLVCiI3qV69elStWpX9+/cXuu78aqGhoYVOWnRzc2PVqlUEBgaydOlS26Vuq1evLtYc/63k7u7OSy+9RJUqVYiKiqJ58+bMmzcPT09P1q9fT1paGpMmTeLee+/lq6++IiYmptDZ+t7e3kRERODs7MzSpUvx9PTkkUceueFaIiMjadOmDUuXLuXIkSOEh4cTFhZ2qw71hjVu3Jjhw4eTl5fHe++9R0hICC+99BJVq1Zl5cqV5ObmEhERQYMGDVi1ahV79+7lhRdeMPTRsmVLxo4di9Vq5f3336dt27a0aNHihuo4ffo0ixYtYtGiRbYRgoLHBec07Nu3DzCexyJys0xWTVSJ3LSXX36Z//mf/+Htt98mODi4rMu5o8TFxfHYY48xatQowsPDWbt2LRMmTCAiIoJHH320rMsrVefPn+f++++nVq1axMTElHU5Ug5o5EDkLwgLC8NkMvHxxx+XdSlyB1u1ahU5OTllOgUj5YvCgchf0LhxY7p3787333/Pf//737IuR+5A586dIyoqCm9vb/r371/W5Ug5oWkFERERMdDIgYiIiBgoHIiIiIiB7nMAWCzXvomNiIhIeeThUfSt30EjByIiIvIHCgciIiJioHAgIiIiBgoHIiIiYqBwICIiIgYKByIiImKgcCAiIiIGCgciIiJioHAgIiIiBgoHIiIiYqBwICIiIgYKByIiImKgcCAiIiIGCgciIiJioCWbS9hDc9aVdQkif1n0uF5lXYKIlCKNHIiIiIiBwoGIiIgYKByIiIiIgcKBiIiIGCgciIiIiIHCgYiIiBgoHIiIiIiBwoGIiIgYKByIiIiIgcKBiIiIGCgciIiIiIHCgYiIiBgoHIiIiIiBwoGIiIgYKByIiIiIgcKBiIiIGCgciIiIiIHCgYiIiBgoHIiIiIiBwoGIiIgYKByIiIiIgcKBiIiIGCgciIiIiIHCgYiIiBgoHIiIiIiBwoGIiIgYKByIiIiIgcKBiIiIGCgciIiIiIFDSXY+Z84c9uzZQ25uLs888wxxcXH88MMPVK5cGYDBgwfTsWNH1q9fz7Jly7CzsyM0NJSQkBBycnIYP348p0+fxt7enoiICLy9vTl06BBTp04FwNfXl2nTpgEQFRVFdHQ0JpOJUaNG0aFDh5I8NBERkXKrxMLBjh07OHr0KKtWreLChQv06tWLNm3aMHPmTBo1amTbLiMjg4ULF7JmzRocHR3p2bMnnTp1YvPmzbi4uDBv3jy2bt3KvHnzeOONN5g5cyYTJ06kSZMmjB49mq1bt1K/fn02btzIypUruXTpEmFhYbRv3x57e/uSOjwREZFyq8SmFe677z7efPNNAKpWrUpmZiapqamFttu3bx/+/v44Ozvj5OREYGAg8fHxxMbG0rlzZwDat2/Pnj17yM7O5tSpUzRp0gSA4OBgYmNjiYuLIygoCLPZjJubG7Vq1eLYsWMldWgiIiLlWomNHNjb21OpUiUAVq9ezf3338/58+dZsGABqampeHl5MWnSJJKTk3Fzc7Pt5+7ujsViMbTb29tjZ2dHcnIyLi4utm09PDywWCy4uroW2Yevr29JHZ6IiEi5VaLnHAB8/fXXrFmzhvfff58dO3bg4+NDvXr1eOedd4iMjCQgIMCwvdVqxWQyYbVaC7UX1Xb133/s43oiIyNZsGABACNGjGD06NE3dXwidwIPD+eyLkFESlGJhoNt27axaNEioqKicHZ2tk0TAHTu3JmpU6fSpUsXtmzZYmtPSkqiadOmeHl5YbFY8PPzIycnB6vViqenJykpKbZtExMT8fT0xMvLi4SEBEO7h4fHdWsLDw8nPDwcAIslDYsl7RYdtUj5o98PkfLneqG/xM45SEtLY86cOSxevBhXV1cAhg0bxunTpwGIi4vj7rvvJiAggP3795Oamkp6ejrx8fEEBgbSrl07oqOjAdi8eTOtWrXC0dGR+vXrs3v3bgA2bdpEUFAQrVu3ZsuWLWRnZ5OYmEhSUhI+Pj4ldWgiIiLlWomNHGzcuJELFy7w7LPP2tp69+5NeHg4lSpVomLFikRERODk5MSYMWMYPHgwJpOJkSNH4uzsTLdu3di+fTv9+vXDbDYze/ZsACZOnMjkyZPJz88nICCAtm3bAtC3b18GDhyIyWRi6tSp2NnpFg4iIiI3w2T944T9Hagkh0wfmrOuxPoWKS3R43qVdQkicouVybSCiIiI3J4UDkRERMRA4UBEREQMFA5ERETEQOFAREREDBQORERExEDhQERERAwUDkRERMRA4UBEREQMFA5ERETEQOFAREREDBQORERExEDhQERERAwUDkRERMRA4UBEREQMFA5ERETEQOFAREREDBQORERExEDhQERERAwUDkRERMRA4UBEREQMFA5ERETEQOFAREREDBQORERExEDhQERERAwUDkRERMRA4UBEREQMFA5ERETEQOFAREREDBQORERExEDhQERERAwUDkRERMRA4UBEREQMFA5ERETEQOFAREREDBzKugC5/dx7lzvhDzfHr5YbOXn5xOxNYP6GPeTm5fNIi/oM6tAY7+rOJKdlsmzLAdbuOFpkPw72dgzv2pTOAXWo7lyRxJQMPt91jKWbDwDwD9fKjH6kBff5/ANHBzt+SbzIe1//yHeHTmFnMjEppA3BTe7iUmYOc/+zky0/nbT1PS20HXU8XHhy4ZdYraXytoiIlBsaOZAb4lm1EguHdOLeOu58tO0gu4+fJax9I8IfbkZQo9q8EtaeyhUceSdmL2mZ2bzUuw1BjWoX2ddTD/rzxAP3YrmYyYKN8eTn5zOqW3O6t6gPwIIhwTzofxfr4o7y4ZafaFizGq893pG6Hi50CajLv1r6sGb7EX4/n8bLfdpSwcEegMAGXnRtWpcZn8YqGIiI3ASNHMgNaedbiyoVzXy28yjvfvUjdiYTzep70bPl3VR3rgjAOzF72Rj/C9sPn2L12H8R0qYh237+vVBf/nXcAYj6+kdij5wmL9/Ki71acY+3O98fOs13h05xMvkQn+44AoBvLTeC/etwd41qBNTz4MKlLCK/jOf+e2oz/8kHqedVleNnU5jwaGs+/u/PHDuTUnpvjIhIOaKRA7khlZyu5MmMyzkA5FutnEvLpEpFM9WqOBmeS7qYAYBf7epF9rXr2FkAgu6pTe3qVWh5dw0Adh49w4X0LN7YsIdPdxzBrYoTzep5ElDXkwuXstjzSyIOdnbk5OUDkJObb+tzcLA/lSo44uVaiZiXQ1gW/jA+NVxv9dsgIlKuKRzIDfnp5DkAgv3r0Kh2dR70v4sGXlc+fPeeSAKgT1tf7nJ35okH7gXAtVKFIvv6cMtPfLrjCKHt/PjP+Ee5/57avB39g+HcAYC143oSNeIhzqdlMnRRDOcvZZGQdJHqzk40retJW7+aZOfmYW9n4rGO93Lk9HmCm9Rh4sfbSL+cy7S+7Urq7RARKZcUDuSG7E1IYvX2w3i5Vuaj0Y/wUu82nEi6CMCe44ns/9VC64Y1WfdiL9r61SItM5vc/Pwi++of1IjerRsSszeBF5dvZdexswzr0pRuzesbthu3fCuz18bh5VqZRc90oXZ1Zz7beZSTyWm8N/Ih+gfdwwebDzD6kRZ8s/9XLufm8cvZFPb8ksi2gyfxq12dShU0gyYiUlwl+i/mnDlz2LNnD7m5uTzzzDP4+/szbtw48vLy8PDwYO7cuZjNZtavX8+yZcuws7MjNDSUkJAQcnJyGD9+PKdPn8be3p6IiAi8vb05dOgQU6dOBcDX15dp06YBEBUVRXR0NCaTiVGjRtGhQ4eSPLQ72ux1cSzf+hNerpX5+fdzvP7EAwCcOpfGUwuj8anhitnenkOnz/PdjH4k/t/0wh8VjCzMXhtHamY2JywXWfV8D/oHNWJj/C8AVHCwZ+fRM+w8egbnimZGPtyM3q0b8uYXe+g3/3P8alUnJT2LZvW8aPCPary4/L/MGhBERnYuAJn/93cVJzMZl3NL+q0RESkXSmzkYMeOHRw9epRVq1YRFRXFrFmzeOutt+jfvz8rVqygVq1arFmzhoyMDBYuXMgHH3zA8uXLiYqKIiUlhQ0bNuDi4sInn3zC008/zbx58wCYOXMmEydOZOXKlaSkpLB161ZOnjzJxo0bWbFiBYsXL2bmzJnk5eWV1KHd0VwrVyCkTUPu8XYn/pdErNYrlzaevZBOFScz/YMa4Whvx4GTyQTU8cDRwd423eBaqQJ1PVxs0wz2diYAHB2u/G9otr9ytYEJaHV3DXZEDCBi4P221y7YPj//yiUI2bn5/PirhdTMbP79SAve/GIPF9KzSMvKxqWi+f/qdSI/30paZnbJvzkiIuVEiY0c3HfffTRp0gSAqlWrkpmZSVxcnO2bfnBwMB988AH16tXD398fZ2dnAAIDA4mPjyc2NpaePXsC0L59eyZNmkR2djanTp2y9RscHExsbCwWi4WgoCDMZjNubm7UqlWLY8eO4evrW1KHd8fKzcvn391aAFCzWmVaNaxJpQqORG6Mx83Zief+GciJpIusiztKSJuG5OTmseK/PwPQt50fz3QJIOrrH3knZi+bD5ykV6u7md4viG0HT/JQs3oAfHvgN/adsJB4MYOgRrV54V/3YUnNpF9QI/Ly89n802+Gmsb0uI9jZy+wftcxAGIPn+aBxnfxdOcmdGtWn70nkmwjCCIi8udKbOTA3t6eSpUqAbB69Wruv/9+MjMzMZuvfKPz8PDAYrGQnJyMm5ubbT93d/dC7fb29tjZ2ZGcnIyLi4tt2z/rQ269S1k5jPlgMyfPpfFMl6bU8XDhzS/28D/bD7Pr2FnmfLaTCo72jHy4GVk5eYxZtoXDp88X2de89btYvvUnarlVYVS35jhXrMDCL3/gg80HyMrJZcSSr9j80290b9GAwcH+nDqXxgsfbuXAb8m2PlreXYNg/zrM+nSHrW3D7uNE701g0P2NyczJ5dV1cSX+voiIlCclfpbW119/zZo1a3j//ffp2rWrrd36f3ensf7hLjVWqxWTyVRke1Ft1+vjeiIjI1mwYAEAI0aMYPTo0TdwVHe2XcfPMuCNDUU+t+r7Q6z6/lCRzy35ah9Lvtpne5yZncsbG/bwxoY9RW5/6vwlxn249bq17Dx6hrYTPza05eTl8/In3113P7kxHh7OZV2CiJSiEg0H27ZtY9GiRURFReHs7EzFihXJysrCycmJxMREPD098fLyYsuWLbZ9kpKSaNq0KV5eXlgsFvz8/MjJycFqteLp6UlKyv/f2ObqPuNqdWkAABlfSURBVBISEgztHh4e160tPDyc8PBwACyWNCyWtFt78CLliH4/RMqf64X+EptWSEtLY86cOSxevBhX1yvXwbdt25aYmBgANm3aRFBQEAEBAezfv5/U1FTS09OJj48nMDCQdu3aER0dDcDmzZtp1aoVjo6O1K9fn927dxv6aN26NVu2bCE7O5vExESSkpLw8fEpqUMTEREp10ps5GDjxo1cuHCBZ5991tY2e/ZsJk2axKpVq6hZsyY9e/bE0dGRMWPGMHjwYEwmEyNHjsTZ2Zlu3bqxfft2+vXrh9lsZvbs2QBMnDiRyZMnk5+fT0BAAG3btgWgb9++DBw4EJPJxNSpU7Gz0y0cREREbobJ+scJ+ztQSQ6ZPjRnXYn1LVJaosf1KusSROQWK5NpBREREbk9KRyIiIiIgcKBiIiIGCgciIiIiIHCgYiIiBgoHIiIiIiBwoGIiIgYKByIiIiIgcKBiIiIGCgciIiIiIHCgYiIiBgoHIiIiIiBwoGIiIgYKByIiIiIgcKBiIiIGCgciIiIiIHCgYiIiBgoHIiIiIiBwoGIiIgYKByIiIiIgcKBiIiIGCgciIiIiIHCgYiIiBgoHIiIiIiBwoGIiIgYKByIiIiIgcKBiIiIGCgciIiIiIHCgYiIiBgoHIiIiIiBwoGIiIgYKByIiIiIgcKBiIiIGCgciIiIiEGxwsH48eMLtQ0ePPiWFyMiIiJlz+F6T65fv56VK1dy9OhRBgwYYGvPzMwkJSWlxIsTERGR0nfdcNCjRw9atWrF2LFjCQ8Pt7Xb2dnh4+NT4sWJiIhI6btuOADw8vJi+fLlpKWlGUYL0tLScHV1LdHiREREpPT9aTgAmDFjBp9++ilubm5YrVYATCYT33zzTYkWJyIiIqWvWOEgLi6OHTt2UKFChZKuR0RERMpYsa5WqFu3roKBiIjIHaJYIwdeXl4MGDCAFi1aYG9vb2sfPXr0dfc7cuQII0aM4IknnmDgwIFMnz6dH374gcqVKwNXLofs2LEj69evZ9myZdjZ2REaGkpISAg5OTmMHz+e06dPY29vT0REBN7e3hw6dIipU6cC4Ovry7Rp0wCIiooiOjoak8nEqFGj6NChw828HyIiIne8YoUDV1dX2rRpc0MdZ2RkMH36dMN+GRkZzJw5k0aNGhnaFi5cyJo1a3B0dKRnz5506tSJzZs34+Liwrx589i6dSvz5s3jjTfeYObMmUycOJEmTZowevRotm7dSv369dm4cSMrV67k0qVLhIWF0b59e0OQERERkeIpVjgYMWLEDXdsNpt59913effdd21t6enphbbbt28f/v7+ODs7AxAYGEh8fDyxsbH07NkTgPbt2zNp0iSys7M5deoUTZo0ASA4OJjY2FgsFgtBQUGYzWbc3NyoVasWx44dw9fX94brFhERudMVKxzcc889mEwm22OTyYSzszNxcXHX7tjBAQcHY/fp6eksWLCA1NRUvLy8mDRpEsnJybi5udm2cXd3x2KxGNrt7e2xs7MjOTkZFxcX27YeHh5YLBZcXV2L7EPhQERE5MYVKxwcOnTI9nN2djaxsbEcPnz4hl8sLCwMHx8f6tWrxzvvvENkZCQBAQGGbaxWKyaTyXbJ5NXtRbVd/fcf+7ieyMhIFixYAFwZGfmz8ydE7mQeHs5lXYKIlKJihYOrmc1mOnTowPvvv8/QoUNvaN/OnTsbfp46dSpdunRhy5YttvakpCSaNm2Kl5cXFosFPz8/cnJysFqteHp6Gm7ElJiYiKenJ15eXiQkJBjaPTw8rltLeHi47a6PFksaFkvaDR2LyJ1Evx8i5c/1Qn+xLmVcs2aN4c+CBQtITEy84UKGDRvG6dOngSv3Trj77rsJCAhg//79pKamkp6eTnx8PIGBgbRr147o6GgANm/eTKtWrXB0dKR+/frs3r0bgE2bNhEUFETr1q3ZsmUL2dnZJCYmkpSUpNs7i4iI3KRijRzs2bPH8LhKlSq88cYb193nwIEDvPrqq5w6dQoHBwdiYmLo168f4eHhVKpUiYoVKxIREYGTkxNjxoxh8ODBmEwmRo4cibOzM926dWP79u3069cPs9nM7NmzAZg4cSKTJ08mPz+fgIAA2rZtC0Dfvn0ZOHAgJpOJqVOnYmen1ahFRERuhsn6xwn760hJScFkMlG1atWSrKnUleSQ6UNz1pVY3yKlJXpcr7IuQURusetNKxRr5CA+Pp5x48aRnp6O1WrF1dWVuXPn4u/vf8uKFBERkb+HYoWDefPm8fbbb9OwYUMADh48yMyZM/n4449LtDgREREpfcWamLezs7MFA7hy3wPdfVBERKR8KnY4iImJ4dKlS1y6dImNGzcqHIiIiJRTxZpWmDZtGtOnT2fSpEnY2dnh5+fHjBkzSro2ERERKQPFGjn4/vvvMZlM7Nq1i7i4OKxWK1u3bi3p2kRERKQMFCscrF+/nnfeecf2+P3332fDhg0lVpSIiIiUnWKFg7y8PBwdHW2Pi1r7QERERMqHYp1z8OCDDxIWFkaLFi3Iz89nx44ddOnSpaRrExERkTJQrHAwYsQIWrZsyY8//ojJZGLKlCk0bdq0pGsTERGRMlDsVRkDAwMJDAwsyVpERETkb0CrE4mIiIiBwoGIiIgYKByIiIiIgcKBiIiIGCgciIiIiIHCgYiIiBgoHIiIiIiBwoGIiIgYKByIiIiIgcKBiIiIGCgciIiIiIHCgYiIiBgoHIiIiIiBwoGIiIgYKByIiIiIgcKBiIiIGCgciIiIiIHCgYiIiBgoHIiIiIiBwoGIiIgYKByIiIiIgcKBiIiIGCgciIiIiIHCgYiIiBgoHIiIiIiBwoGIiIgYKByIiIiIgcKBiIiIGCgciIiIiIHCgYiIiBiUaDg4cuQInTp14qOPPgLgzJkzDBo0iP79+zN69Giys7MBWL9+Pb1796ZPnz6sWbMGgJycHMaMGUO/fv0YOHAgJ0+eBODQoUOEhYURFhbGlClTbK8VFRVFSEgIffr0YevWrSV5WCIiIuVaiYWDjIwMpk+fTps2bWxtb731Fv3792fFihXUqlWLNWvWkJGRwcKFC/nggw9Yvnw5UVFRpKSksGHDBlxcXPjkk094+umnmTdvHgAzZ85k4sSJrFy5kpSUFLZu3crJkyfZuHEjK1asYPHixcycOZO8vLySOjQREZFyrcTCgdls5t1338XT09PWFhcXR3BwMADBwcHExsayb98+/P39cXZ2xsnJicDAQOLj44mNjaVz584AtG/fnj179pCdnc2pU6do0qSJoY+4uDiCgoIwm824ublRq1Ytjh07VlKHJiIiUq6VWDhwcHDAycnJ0JaZmYnZbAbAw8MDi8VCcnIybm5utm3c3d0Ltdvb22NnZ0dycjIuLi62bf+sDxEREblxDqX5YiaTyfaz1Wo1/H11u8lkKrK9qLbr9XE9kZGRLFiwAIARI0YwevToGzgSkTuLh4dzWZcgIqWoVMNBxYoVycrKwsnJicTERDw9PfHy8mLLli22bZKSkmjatCleXl5YLBb8/PzIycnBarXi6elJSkqKbdur+0hISDC0e3h4XLeW8PBwwsPDAbBY0rBY0m7twYqUI/r9ECl/rhf6S/VSxrZt2xITEwPApk2bCAoKIiAggP3795Oamkp6ejrx8fEEBgbSrl07oqOjAdi8eTOtWrXC0dGR+vXrs3v3bkMfrVu3ZsuWLWRnZ5OYmEhSUhI+Pj6leWgiIiLlRomNHBw4cIBXX32VU6dO4eDgQExMDK+99hrjx49n1apV1KxZk549e+Lo6MiYMWMYPHgwJpOJkSNH4uzsTLdu3di+fTv9+vXDbDYze/ZsACZOnMjkyZPJz88nICCAtm3bAtC3b18GDhyIyWRi6tSp2NnpFg4iIiI3w2T944T9Hagkh0wfmrOuxPoWKS3R43qVdQkicov9baYVRERE5O9P4UBEREQMFA5ERETEQOFAREREDBQORERExEDhQERERAwUDkRERMRA4UBEREQMFA5ERETEQOFAREREDBQORERExEDhQERERAwUDkRERMRA4UBEREQMFA5ERETEQOFAREREDBQORERExEDhQERERAwUDkRERMRA4UBEREQMFA5ERETEQOFAREREDBQORERExEDhQERERAwUDkRERMRA4UBEREQMFA5ERETEQOFAREREDBQORERExEDhQERERAwUDkRERMRA4UBEREQMFA5ERETEQOFAREREDBQORERExEDhQERERAwUDkRERMRA4UBEREQMFA5ERETEQOFAREREDBQORERExMChNF/swIEDjBgxgjp16gDQsGFDhgwZwrhx48jLy8PDw4O5c+diNptZv349y5Ytw87OjtDQUEJCQsjJyWH8+PGcPn0ae3t7IiIi8Pb25tChQ0ydOhUAX19fpk2bVpqHJSIiUq6U6shBRkYGXbt2Zfny5SxfvpyXX36Zt956i/79+7NixQpq1arFmjVryMjIYOHChXzwwQcsX76cqKgoUlJS2LBhAy4uLnzyySc8/fTTzJs3D4CZM2cyceJEVq5cSUpKClu3bi3NwxIRESlXSjUcpKenF2qLi4sjODgYgODgYGJjY9m3bx/+/v44Ozvj5OREYGAg8fHxxMbG0rlzZwDat2/Pnj17yM7O5tSpUzRp0sTQh4iIiNycUp1WyMjIYM+ePQwZMoTMzEzCw8PJzMzEbDYD4OHhgcViITk5GTc3N9t+7u7uhdrt7e2xs7MjOTkZFxcX27YFfYiIiMjNKdVw4Ofnx8iRIwkODiYhIYEnn3yS3Nxc2/NWq9Xw99XtJpOpyPai2oojMjKSBQsWADBixAhGjx59w8cjcqfw8HAu6xJEpBSVajho0KABDRo0AKBevXq4u7tz5swZsrKycHJyIjExEU9PT7y8vNiyZYttv6SkJJo2bYqXlxcWiwU/Pz9ycnKwWq14enqSkpJi27agjz8THh5OeHg4ABZLGhZL2q09WJFyRL8fIuXP9UJ/qZ5zsGbNGj788EMALBYL586d49FHHyUmJgaATZs2ERQUREBAAPv37yc1NZX09HTi4+MJDAykXbt2REdHA7B582ZatWqFo6Mj9evXZ/fu3YY+RERE5OaYrMUdh78FLl68yNixY8nIyCA7O5tRo0bRqFEjXnzxRS5fvkzNmjWJiIjA0dGR6Oho3nvvPUwmEwMHDqRHjx7k5eUxadIkTpw4gdlsZvbs2dSoUYNjx44xefJk8vPzCQgIYMKECTdUV0l+K3pozroS61uktESP61XWJYjILXa9kYNSDQd/VwoHItencCBS/vxtphVERETk70/hQERERAwUDkRERMRA4UBEREQMFA5ERETEQOFAREREDBQORERExEDhQERERAwUDkRERMRA4UBEREQMFA5ERETEQOFAREREDBQORERExEDhQERERAwUDkRERMRA4UBEREQMFA5ERETEQOFAREREDBQORERExEDhQERERAwUDkRERMRA4UBEREQMFA5ERETEQOFAREREDBQORERExEDhQERERAwUDkRERMRA4UBEREQMFA5ERETEQOFAREREDBQORERExEDhQETkNhUXF8vjj4fRufP9/Pvfwzh9+lShbZKTLfz738No3z6Q5cs/sLWHhPyT9u0DDX9GjRoKwIEDP/L004/TqVN7BgwIISZmIwA///wTYWG96NKlAx9++L6tr1Onfqdr1w6cPPlbyR6wlBqFAxGR21BGRjpTpkygShVnpk6dyS+/HOe11yIM2yQlJfL442GcO5dcaP9Zs+ayaNFSFi1ayrx5kZjNFWjY0JfLl7MYN+45TCYTERHzcHFxYdasafz++0kWL15I/fo+jBr1LFFRi0hOtgDw5puv8eijffH2vqtUjl1KnsKBiMhtaPfuXVy6dIlevUJo1y6IDh0eYPfunVy6dMm2TVZWFkOHjmTMmPGF9m/Y0I977/Xn3nv9iY39HrPZkccfH8zFixfp3bsvzz8/jvvua0WXLt3Iy8vjxIkEzp49Q5s27ejW7Z/k5+dz5sxpvv9+G8eOHeWxx54qzcOXEqZwICJyGzp16ncA3N09AKhe3Z38/HxbO8Bdd9XhX/969Lr9/P77SdatW01o6ACqVnXF09OLwYOfwde3EampqcTGfkelSpVp1Oge3N09SEg4zvHjxwBwda3GW2/NIyioA48/Hsa//tWVb7/9uoSOWEqTwoGIyG3o8uUsABwcHABwdHQErowW3Ihly97DbDbTu3dfQ/u2bVvp1u1BDh78iRkzXqV6dXf69OnH2rWrGTx4IMHBXfjmm03UqFGTgwcP0KNHL0aNeo433piL1Wq9BUcoZUnhQETkNlShghMAubm5AOTk5ABQsaJTsftIT7/E11/HEBTUEReXqobnmjVrwcKFUdx7rz8TJ47l+PFjdOjwAOvWfcknn6xl+PBwVq78iOeeG8exY0fx9W2En989nD9/jnPnzt2io5SyonAgInIb8vb2Bq6cdAhw9uwZ7O3tqV3bu9h9fP/9d+Tk5NCu3f22tt9+O8HHHy/j3LlkAgKaEhISRlZWFnFxsQBUq1YNb++7iIx8nR49HqVOnbo4OprJy8uzBRQnp+IHFPl7UjgQEbkNtWjRkqpVq7J+/Tq2b/+O7du30bZtez79dDUPPdSRQ4cOcuHCBTZv/pq9e+MBSEg4zubNX3P27BkADh/+GYC7777b1m9eXj5LlrzN/Plz2LNnF5999ikAPj7/v82uXXEcPPgTTzwxBIAGDRrwzTeb2Ljxc7y8/kGVKlVK5T2QkqNwICJyG6pYsSKvvDKbixdTmDJlIj4+DRkzZjzZ2Ze5dOkSubl5JCQc5+WXx/P++0sA2LTpS15+eTzx8buB/x91KDipEaBevfpMmTKTxMRExowJ5/Dhnxk+PJyWLVsDV6Yx3nhjLiNHjqZSpUoADB/+b/bujWfTpi957rkXSvNtkBJisurMESyWtBLr+6E560qsb5HSEj2uV1mXICK3mIeH8zWfcyjFOkrcrFmz2LdvHyaTiYkTJ9KkSZOyLklEROS2U27Cwc6dO/n1119ZtWoVx44dY8KECaxevbqsyxIREbntlJtzDmJjY+nUqRMAPj4+pKamGu4UJiIiIsVTbsJBcnIy1apVsz2uXr06FoulDCsSERG5PZWbaYU/nldptVoxmUzX3D4yMpIFCxYAMGrUKMLDw0ukrj1zHyuRfuX/RUZGlth/PxG5Nv3ulV/l5mqFyMhIPDw8CAsLAyA4OJj//Oc/ut72DuDr68vhw4fLugyRO45+98qvcjOt0K5dO2JiYgA4ePAgnp6eCgYiIiI3odxMKzRv3pzGjRsTFhaGyWRiypQpZV2SiIjIbanchAOAsWPHlnUJUgZGjRpV1iWI3JH0u1d+lZtzDkREROTWKDfnHIiIiMitoXAgIiIiBgoHIiIiYqBwICIiIgYKByIiImKgcCC3tVmzZhEaGkpYWBg//vhjWZcjcsc4cuQInTp14qOPPirrUqQElKv7HMidRct0i5SNjIwMpk+fTps2bcq6FCkhGjmQ25aW6RYpG2azmXfffRdPT8+yLkVKiMKB3La0TLdI2XBwcMDJyamsy5ASpHAgt60bXaZbRESKR+FAblteXl4kJyfbHiclJeHu7l6GFYmIlA8KB3Lb0jLdIiIlQwsvyW3ttddeY/fu3bZluv38/Mq6JJFy78CBA7z66qucOnUKBwcHvLy8iIyMxNXVtaxLk1tE4UBEREQMNK0gIiIiBgoHIiIiYqBwICIiIgYKByIiImKgcCAiIiIGWnhJRG6Zixcv8uqrr3LgwAEqV64MQHh4OGfPnmX79u289tprZVyhiBSHwoGI3BJWq5UhQ4bQs2dPZs2aBcDhw4d56qmnePbZZ8u4OhG5EQoHInJLxMbGAjBgwABbm6+vLxs3buSbb76xtX311VdERUVhNpvJy8tjzpw51K5dm2XLlrF+/XoqVqyIk5MTc+fOJTs7m7FjxwKQlZVFaGgoISEhpXtgIncghQMRuSWOHj1KkyZNCrVXrVrV8Dg1NZX58+dTs2ZNFi9ezMcff8yLL77IW2+9RUxMDO7u7mzbto2kpCRiY2OpX78+06ZN4/Lly6xevbq0DkfkjqZwICK3hL29PXl5eX+6XfXq1XnxxRexWq1YLBaaNWsGQEhICEOGDKFr16489NBD1KtXDwcHB1asWMH48ePp0KEDoaGhJX0YIoKuVhCRW6Rhw4b88MMPhdoPHz5MZmYmADk5OTz33HNMnz6djz76iEGDBtm2mzBhAgsXLqRq1aqMHDmSrVu30qBBA7744gt69OhBbGysYXsRKTkKByJyS7Rs2ZLKlSuzZMkSW9vRo0cZPnw4dnZX/qlJT08nPz+fGjVqcPnyZb755huys7O5ePEikZGR1KhRg/79+zNgwAD279/P559/zv79+2nbti1TpkzhzJkz5ObmltUhitwxNK0gIrfMkiVLiIiIoHv37ri6ulKhQgXeeOMNjh07BoCrqys9e/akb9++1KxZk8GDBzNu3Di2b99Oeno6ISEhuLi44ODgwMyZMzl//jxTpkzBbDZjtVp5+umncXDQP1siJU2rMoqIiIiBphVERETEQOFAREREDBQORERExEDhQERERAwUDkRERMRA4UBEREQMFA5ERETEQOFAREREDP4XPaxV6xNGU20AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fraudcount = len(df[df['Class'] == 1])/len(df['Class'])\n",
    "\n",
    "print(fraudcount)\n",
    "\n",
    "#visual rep of the classes\n",
    "sns.countplot('Class', data = df)\n",
    "plt.title('Data Distribution\\n (Non-Fraud: 0 || Fraud: 1)', fontsize = 14, fontweight = 'bold')\n",
    "plt.annotate((str(round(fraudcount*100, 3)) + '%'), xy=(.85, 5000.5), fontsize = 12, fontweight = 'bold')\n",
    "plt.annotate((str(round(100 - fraudcount*100, 2)) + '%'), xy=(-.17, 200000.5), \n",
    "             fontsize = 14, fontweight = 'bold', color = 'white');\n",
    "\n",
    "#how do you add the labels?\n",
    "#KWARGS key word arguments found:\n",
    "#https://matplotlib.org/api/text_api.html#matplotlib.text.Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data\n",
    "#so you have ytest before further data manipulation\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "X = df.drop(['Class'], axis = 1)\n",
    "y = df['Class']\n",
    "\n",
    "fivestratfolds = StratifiedKFold(n_splits = 5, shuffle = False, random_state = 42)\n",
    "#this feeds in parameters, telling sklearn how to split data\n",
    "\n",
    "#is there a difference if you put shuffle on your kfolds or not?\n",
    "# your data is not a time series data, or ordered data (where you must maintain the flow)\n",
    "#so you can shuffle if you want\n",
    "\n",
    "whatevergenerator = fivestratfolds.split(X, y)\n",
    "#this is the actionable function that splits the data\n",
    "#also this splits X up with respect to y, meaning y is the stratified variable\n",
    "#its also a generator object (lazy), meaning that you will have to call upon it to get your results\n",
    "\n",
    "for training, testing in whatevergenerator:\n",
    "    Xtraining, ytraining = X.iloc[training], y.iloc[training]\n",
    "    Xtesting, ytesting = X.iloc[testing], y.iloc[testing]\n",
    "#NOTE! the split returns the test index! so 'training' returns the index for the values!\n",
    "#not the values themselves!\n",
    "#so you need to call on pandas dataframe, then feed in the index to get your training and testing sets\n",
    "    #rmb for pandas, iloc is for indexed, loc is for 'named' data\n",
    "    #if no iloc[,] comma is passed, pandas will slice the entire row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df columns: 31\n",
      "Xtesting columns: 30 (because you dropped y column)\n"
     ]
    }
   ],
   "source": [
    "print('df columns:', len(df.iloc[1,:]))\n",
    "print('Xtesting columns:', len(Xtesting.columns), '(because you dropped y column)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#okay with the StratifiedKFold split above\n",
    "#you have 20% of your data as a test set and 80% as training set\n",
    "\n",
    "#you should do your over and undersampling on the 80% training set\n",
    "\n",
    "# Xtraining['classagain'] = ytraining\n",
    "\n",
    "# trainingdf = Xtraining\n",
    "\n",
    "#because you did not drop with inplace = True, will Xtraining['Class'] = ytraining\n",
    "#rewrite in your core dataframe???\n",
    "#also is newdf = df.drop(whatever)\n",
    "#the sam as df.drop(whatever, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what's the way to do under and oversampling with the outlier detection\n",
    "#undersample first RUS or nearmiss, up to you\n",
    "#then outlier detection\n",
    "#then remove interquartile range\n",
    "#then you do your oversampling\n",
    "#should ask the TAs about this\n",
    "#WWWWWWWWWWWWWWWWWWWWWWWWWWw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of Xtraining:  227846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of Xresampled(w ADASYN):  228235\n",
      "size of Xresampled(w ADASYN + undersampling):  1566\n"
     ]
    }
   ],
   "source": [
    "#since ADASYN relies on the decision line\n",
    "#you should do oversampling first, then undersampling - so that when you scale to bigger data sets\n",
    "#it will more closely emulate the decision line/boundary\n",
    "\n",
    "print('size of Xtraining: ', len(Xtraining))\n",
    "\n",
    "from imblearn.over_sampling import ADASYN, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "doublefraudpercent = ADASYN(sampling_strategy='minority', random_state=None, n_neighbors=5, n_jobs=1, ratio=fraudcount * 2)\n",
    "\n",
    "Xresampled, yresampled = doublefraudpercent.fit_resample(Xtraining, ytraining)\n",
    "print('size of Xresampled(w ADASYN): ', len(Xresampled))\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42, ratio = 1)\n",
    "\n",
    "Xresampled, yresampled = rus.fit_resample(Xresampled, yresampled)\n",
    "print('size of Xresampled(w ADASYN + undersampling): ', len(Xresampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-SNE took 1.6e+01 s\n",
      "PCA took 0.0046 s\n"
     ]
    }
   ],
   "source": [
    "#'see' the data through dimensionality reduction (PCA, TSNE, etc)\n",
    "\n",
    "import time\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# T-SNE Implementation\n",
    "t0 = time.time()\n",
    "X_reduced_tsne = TSNE(n_components=2, random_state=42).fit_transform(Xresampled)\n",
    "t1 = time.time()\n",
    "print(\"T-SNE took {:.2} s\".format(t1 - t0))\n",
    "\n",
    "# PCA Implementation\n",
    "t0 = time.time()\n",
    "X_reduced_pca = PCA(n_components=2, random_state=42).fit(Xresampled)\n",
    "t1 = time.time()\n",
    "print(\"PCA took {:.2} s\".format(t1 - t0))\n",
    "\n",
    "#to get .components_ .get_covariance() etc. it needs to be .fit(whatever)\n",
    "#not .fit_transform(whatever)\n",
    "#because fit_transform applies the dimensionality reduction on X already\n",
    "#there's no variance to explain from there onward!!!\n",
    "\n",
    "# # TruncatedSVD\n",
    "# t0 = time.time()\n",
    "# X_reduced_svd = TruncatedSVD(n_components=2, algorithm='randomized', random_state=42).fit_transform(Xresampled)\n",
    "# t1 = time.time()\n",
    "# print(\"Truncated SVD took {:.2} s\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.44117244e+01, -1.40592605e+01,  2.52971052e+01,\n",
       "        -9.06447470e+00,  1.62238910e+01,  2.63580098e+00,\n",
       "         2.31950988e+01, -1.84865704e+00,  6.93935818e+00,\n",
       "         1.55495845e+01, -7.25950051e+00,  1.30989126e+01,\n",
       "        -4.12520773e-01,  1.05069644e+01,  6.93913195e-01,\n",
       "         1.03830775e+01,  1.87534450e+01,  7.32413724e+00,\n",
       "        -1.86507427e+00, -1.82052698e+00,  1.57484878e-02,\n",
       "        -1.60243062e-01, -4.03040697e-01, -1.22342573e-01,\n",
       "        -1.63841192e-01,  8.41829781e-02,  4.55283232e-01,\n",
       "         1.33593726e-01,  1.20530604e-01,  5.22942338e-01],\n",
       "       [-1.40592605e+01,  1.12085251e+01, -1.63414288e+01,\n",
       "         6.06579794e+00, -1.04072052e+01, -1.86725058e+00,\n",
       "        -1.48462945e+01,  1.68297352e+00, -4.58401968e+00,\n",
       "        -1.02919567e+01,  5.01976949e+00, -9.00544737e+00,\n",
       "         3.02517202e-01, -7.40881463e+00, -4.16377705e-01,\n",
       "        -7.09990431e+00, -1.27453772e+01, -4.93408433e+00,\n",
       "         1.31866444e+00,  1.14131867e+00,  1.12961497e-01,\n",
       "         1.09114861e-01,  2.08532641e-01,  7.52043203e-02,\n",
       "         9.77061056e-02, -3.55456486e-02, -2.01636669e-01,\n",
       "        -6.92201622e-02, -6.90715354e-02, -3.62448532e-01],\n",
       "       [ 2.52971052e+01, -1.63414288e+01,  3.24302062e+01,\n",
       "        -1.17441296e+01,  1.90493467e+01,  3.86833420e+00,\n",
       "         2.70910130e+01, -4.34973113e+00,  8.72914695e+00,\n",
       "         1.96485308e+01, -1.01149672e+01,  1.80227277e+01,\n",
       "        -6.50483107e-01,  1.52688514e+01,  6.88734149e-01,\n",
       "         1.41176154e+01,  2.51560250e+01,  9.63349482e+00,\n",
       "        -2.72585716e+00, -2.02140416e+00, -5.20971191e-01,\n",
       "        -2.15867956e-01, -2.54018879e-01, -1.29291561e-01,\n",
       "        -1.59963460e-01,  1.79420236e-02,  1.38226223e-01,\n",
       "         8.46321232e-02,  1.05375545e-01,  7.32348346e-01],\n",
       "       [-9.06447470e+00,  6.06579794e+00, -1.17441296e+01,\n",
       "         7.39360414e+00, -7.19904922e+00, -1.97298400e+00,\n",
       "        -1.01432364e+01,  3.08366131e+00, -3.68295081e+00,\n",
       "        -8.34452634e+00,  4.87396918e+00, -8.55713092e+00,\n",
       "         3.55589748e-01, -7.70766141e+00, -1.77012828e-01,\n",
       "        -6.60803831e+00, -1.15793247e+01, -4.32374039e+00,\n",
       "         1.38428199e+00,  6.87159415e-01,  5.53326458e-01,\n",
       "         9.98941933e-02, -4.88445687e-02,  3.93748051e-02,\n",
       "         3.90373238e-02,  4.66742830e-02,  2.09643220e-01,\n",
       "         1.57396206e-02, -1.59400863e-02, -3.54953442e-01],\n",
       "       [ 1.62238910e+01, -1.04072052e+01,  1.90493467e+01,\n",
       "        -7.19904922e+00,  1.43150589e+01,  2.27690174e+00,\n",
       "         1.72228480e+01, -2.25953740e+00,  5.40534601e+00,\n",
       "         1.21479966e+01, -6.05273735e+00,  1.08289252e+01,\n",
       "        -3.74594550e-01,  9.01504691e+00,  4.65961403e-01,\n",
       "         8.51555149e+00,  1.52417101e+01,  5.87523906e+00,\n",
       "        -1.60652496e+00, -1.30930836e+00, -2.06672971e-01,\n",
       "        -1.30607340e-01, -2.11526146e-01, -8.53358454e-02,\n",
       "        -1.08944193e-01,  2.99648574e-02,  1.78734259e-01,\n",
       "         7.02890810e-02,  7.51646203e-02,  4.37514804e-01],\n",
       "       [ 2.63580098e+00, -1.86725058e+00,  3.86833420e+00,\n",
       "        -1.97298400e+00,  2.27690174e+00,  3.09008788e+00,\n",
       "         3.16384843e+00, -1.64653752e+00,  1.34388790e+00,\n",
       "         3.06764220e+00, -2.03167135e+00,  3.52043856e+00,\n",
       "        -1.63635840e-01,  3.34093643e+00,  1.71648012e-02,\n",
       "         2.68333771e+00,  4.62846253e+00,  1.68595865e+00,\n",
       "        -6.02915661e-01, -1.81547720e-01, -3.41177530e-01,\n",
       "        -4.01323960e-02,  8.29734101e-02, -8.03080970e-03,\n",
       "        -2.36287441e-03, -3.96825070e-02, -1.88393540e-01,\n",
       "        -2.72265840e-02, -6.09266278e-03,  1.48714690e-01],\n",
       "       [ 2.31950988e+01, -1.48462945e+01,  2.70910130e+01,\n",
       "        -1.01432364e+01,  1.72228480e+01,  3.16384843e+00,\n",
       "         2.67832038e+01, -2.99289506e+00,  7.64149423e+00,\n",
       "         1.71647282e+01, -8.45889679e+00,  1.51550164e+01,\n",
       "        -5.16471840e-01,  1.25403512e+01,  6.77047188e-01,\n",
       "         1.19332505e+01,  2.13913096e+01,  8.26395990e+00,\n",
       "        -2.23335051e+00, -1.87768873e+00, -2.38369551e-01,\n",
       "        -1.83216312e-01, -3.24201150e-01, -1.23086593e-01,\n",
       "        -1.58603544e-01,  5.11115545e-02,  2.95901909e-01,\n",
       "         1.07666358e-01,  1.10860251e-01,  6.11096220e-01],\n",
       "       [-1.84865704e+00,  1.68297352e+00, -4.34973113e+00,\n",
       "         3.08366131e+00, -2.25953740e+00, -1.64653752e+00,\n",
       "        -2.99289506e+00,  6.08976918e+00, -1.92794190e+00,\n",
       "        -4.46635356e+00,  3.64304498e+00, -6.19542030e+00,\n",
       "         3.32232252e-01, -6.31324668e+00,  1.11818252e-01,\n",
       "        -4.63234136e+00, -7.80007430e+00, -2.73010759e+00,\n",
       "         1.14630607e+00,  6.13838011e-02,  8.90131885e-01,\n",
       "         6.81656496e-02, -3.06468030e-01, -6.70977094e-03,\n",
       "        -3.07930928e-02,  1.22095331e-01,  5.92188700e-01,\n",
       "         1.00865665e-01,  4.30024844e-02, -2.68566905e-01],\n",
       "       [ 6.93935818e+00, -4.58401968e+00,  8.72914695e+00,\n",
       "        -3.68295081e+00,  5.40534601e+00,  1.34388790e+00,\n",
       "         7.64149423e+00, -1.92794190e+00,  4.88978868e+00,\n",
       "         6.01814274e+00, -3.37670001e+00,  5.95525734e+00,\n",
       "        -2.37459132e-01,  5.26597893e+00,  1.55313360e-01,\n",
       "         4.61914023e+00,  8.13662322e+00,  3.06265253e+00,\n",
       "        -9.44092587e-01, -5.36601217e-01, -3.19556185e-01,\n",
       "        -7.00770932e-02, -2.29663861e-03, -3.21166802e-02,\n",
       "        -3.50728606e-02, -2.06624683e-02, -8.69473131e-02,\n",
       "         1.02247280e-03,  1.83944238e-02,  2.45476773e-01],\n",
       "       [ 1.55495845e+01, -1.02919567e+01,  1.96485308e+01,\n",
       "        -8.34452634e+00,  1.21479966e+01,  3.06764220e+00,\n",
       "         1.71647282e+01, -4.46635356e+00,  6.01814274e+00,\n",
       "         1.58382168e+01, -7.68628306e+00,  1.35457496e+01,\n",
       "        -5.43842836e-01,  1.20143949e+01,  3.41331704e-01,\n",
       "         1.04990751e+01,  1.84784220e+01,  6.94634826e+00,\n",
       "        -2.15459023e+00, -1.19884309e+00, -7.51218345e-01,\n",
       "        -1.59189493e-01,  8.26711079e-03, -7.12996456e-02,\n",
       "        -7.68374304e-02, -5.13928090e-02, -2.19685201e-01,\n",
       "        -2.12661421e-03,  3.91254682e-02,  5.58934391e-01],\n",
       "       [-7.25950051e+00,  5.01976949e+00, -1.01149672e+01,\n",
       "         4.87396918e+00, -6.05273735e+00, -2.03167135e+00,\n",
       "        -8.45889679e+00,  3.64304498e+00, -3.37670001e+00,\n",
       "        -7.68628306e+00,  7.09269579e+00, -8.46837098e+00,\n",
       "         3.79043401e-01, -7.89369603e+00, -8.80784513e-02,\n",
       "        -6.48435601e+00, -1.12474622e+01, -4.13360161e+00,\n",
       "         1.42221519e+00,  5.21742775e-01,  7.25255642e-01,\n",
       "         9.73487522e-02, -1.46733774e-01,  2.61844173e-02,\n",
       "         1.71982033e-02,  7.82391967e-02,  3.67311559e-01,\n",
       "         4.80490509e-02,  4.02142612e-03, -3.55473899e-01],\n",
       "       [ 1.30989126e+01, -9.00544737e+00,  1.80227277e+01,\n",
       "        -8.55713092e+00,  1.08289252e+01,  3.52043856e+00,\n",
       "         1.51550164e+01, -6.19542030e+00,  5.95525734e+00,\n",
       "         1.35457496e+01, -8.46837098e+00,  1.69876470e+01,\n",
       "        -6.53572409e-01,  1.36888673e+01,  1.76222605e-01,\n",
       "         1.13161971e+01,  1.96588205e+01,  7.24248437e+00,\n",
       "        -2.46519792e+00, -9.50632211e-01, -1.21775453e+00,\n",
       "        -1.70066191e-01,  2.30094830e-01, -4.89701743e-02,\n",
       "        -3.55635016e-02, -1.28010436e-01, -5.98528039e-01,\n",
       "        -7.52804767e-02, -1.84801939e-03,  6.18472907e-01],\n",
       "       [-4.12520773e-01,  3.02517202e-01, -6.50483107e-01,\n",
       "         3.55589748e-01, -3.74594550e-01, -1.63635840e-01,\n",
       "        -5.16471840e-01,  3.32232252e-01, -2.37459132e-01,\n",
       "        -5.43842836e-01,  3.79043401e-01, -6.53572409e-01,\n",
       "         2.25941069e+00, -6.32189744e-01,  7.23858922e-04,\n",
       "        -4.95688280e-01, -8.49770693e-01, -3.06476448e-01,\n",
       "         1.14279592e-01,  2.65976658e-02,  7.13168234e-02,\n",
       "         7.38285029e-03, -1.98218383e-02,  9.17044808e-04,\n",
       "        -5.23678161e-04,  8.80602192e-03,  4.21520099e-02,\n",
       "         6.51258986e-03,  2.01991198e-03, -2.77976804e-02],\n",
       "       [ 1.05069644e+01, -7.40881463e+00,  1.52688514e+01,\n",
       "        -7.70766141e+00,  9.01504691e+00,  3.34093643e+00,\n",
       "         1.25403512e+01, -6.31324668e+00,  5.26597893e+00,\n",
       "         1.20143949e+01, -7.89369603e+00,  1.36888673e+01,\n",
       "        -6.32189744e-01,  1.51786084e+01,  7.98733666e-02,\n",
       "         1.04421979e+01,  1.80292271e+01,  6.57758078e+00,\n",
       "        -2.33649341e+00, -7.29791394e-01, -1.29985116e+00,\n",
       "        -1.56278259e-01,  3.07800813e-01, -3.31538266e-02,\n",
       "        -1.24189326e-02, -1.49470103e-01, -7.08453327e-01,\n",
       "        -1.00972651e-01, -2.07064912e-02,  5.77628470e-01],\n",
       "       [ 6.93913195e-01, -4.16377705e-01,  6.88734149e-01,\n",
       "        -1.77012828e-01,  4.65961403e-01,  1.71648012e-02,\n",
       "         6.77047188e-01,  1.11818252e-01,  1.55313360e-01,\n",
       "         3.41331704e-01, -8.80784513e-02,  1.76222605e-01,\n",
       "         7.23858922e-04,  7.98733666e-02,  2.25728014e+00,\n",
       "         1.52430787e-01,  3.01239073e-01,  1.32115529e-01,\n",
       "        -1.30045658e-02, -6.10787518e-02,  4.12780581e-02,\n",
       "        -2.50463863e-03, -2.81653377e-02, -4.60031612e-03,\n",
       "        -7.15847681e-03,  8.54032472e-03,  4.30709890e-02,\n",
       "         9.30297905e-03,  6.19719703e-03,  6.06395406e-03],\n",
       "       [ 1.03830775e+01, -7.09990431e+00,  1.41176154e+01,\n",
       "        -6.60803831e+00,  8.51555149e+00,  2.68333771e+00,\n",
       "         1.19332505e+01, -4.63234136e+00,  4.61914023e+00,\n",
       "         1.04990751e+01, -6.48435601e+00,  1.13161971e+01,\n",
       "        -4.95688280e-01,  1.04421979e+01,  1.52430787e-01,\n",
       "         1.09147794e+01,  1.51143101e+01,  5.58162719e+00,\n",
       "        -1.87963896e+00, -7.60320905e-01, -8.98302183e-01,\n",
       "        -1.30687996e-01,  1.56841212e-01, -4.00870730e-02,\n",
       "        -3.15291658e-02, -9.17699349e-02, -4.27093611e-01,\n",
       "        -5.12582160e-02,  2.52039109e-03,  4.73340370e-01],\n",
       "       [ 1.87534450e+01, -1.27453772e+01,  2.51560250e+01,\n",
       "        -1.15793247e+01,  1.52417101e+01,  4.62846253e+00,\n",
       "         2.13913096e+01, -7.80007430e+00,  8.13662322e+00,\n",
       "         1.84784220e+01, -1.12474622e+01,  1.96588205e+01,\n",
       "        -8.49770693e-01,  1.80292271e+01,  3.01239073e-01,\n",
       "         1.51143101e+01,  2.85733976e+01,  9.75733483e+00,\n",
       "        -3.24348951e+00, -1.38706118e+00, -1.48623995e+00,\n",
       "        -2.27666223e-01,  2.31311460e-01, -7.49869202e-02,\n",
       "        -6.37389842e-02, -1.46019693e-01, -6.75099226e-01,\n",
       "        -7.54643757e-02,  1.26589492e-02,  8.20542654e-01],\n",
       "       [ 7.32413724e+00, -4.93408433e+00,  9.63349482e+00,\n",
       "        -4.32374039e+00,  5.87523906e+00,  1.68595865e+00,\n",
       "         8.26395990e+00, -2.73010759e+00,  3.06265253e+00,\n",
       "         6.94634826e+00, -4.13360161e+00,  7.24248437e+00,\n",
       "        -3.06476448e-01,  6.57758078e+00,  1.32115529e-01,\n",
       "         5.58162719e+00,  9.75733483e+00,  5.85775987e+00,\n",
       "        -1.18224059e+00, -5.49418091e-01, -5.04428698e-01,\n",
       "        -8.42405222e-02,  6.13392150e-02, -3.07276828e-02,\n",
       "        -2.86835037e-02, -4.60175257e-02, -2.09923059e-01,\n",
       "        -1.99215124e-02,  9.46765951e-03,  3.01275441e-01],\n",
       "       [-1.86507427e+00,  1.31866444e+00, -2.72585716e+00,\n",
       "         1.38428199e+00, -1.60652496e+00, -6.02915661e-01,\n",
       "        -2.23335051e+00,  1.14630607e+00, -9.44092587e-01,\n",
       "        -2.15459023e+00,  1.42221519e+00, -2.46519792e+00,\n",
       "         1.14279592e-01, -2.33649341e+00, -1.30045658e-02,\n",
       "        -1.87963896e+00, -3.24348951e+00, -1.18224059e+00,\n",
       "         2.64941520e+00,  1.28919196e-01,  2.36901631e-01,\n",
       "         2.81198997e-02, -5.69897775e-02,  5.76813084e-03,\n",
       "         1.89697658e-03,  2.74254039e-02,  1.30115737e-01,\n",
       "         1.86983152e-02,  4.04256127e-03, -1.04090402e-01],\n",
       "       [-1.82052698e+00,  1.14131867e+00, -2.02140416e+00,\n",
       "         6.87159415e-01, -1.30930836e+00, -1.81547720e-01,\n",
       "        -1.87768873e+00,  6.13838011e-02, -5.36601217e-01,\n",
       "        -1.19884309e+00,  5.21742775e-01, -9.50632211e-01,\n",
       "         2.65976658e-02, -7.29791394e-01, -6.10787518e-02,\n",
       "        -7.60320905e-01, -1.38706118e+00, -5.49418091e-01,\n",
       "         1.28919196e-01,  2.37941525e+00, -2.30084924e-02,\n",
       "         1.18151244e-02,  4.13595391e-02,  1.04518817e-02,\n",
       "         1.45284014e-02, -1.00536994e-02, -5.27132059e-02,\n",
       "        -1.36917413e-02, -1.11836149e-02, -3.74345178e-02],\n",
       "       [ 1.57484878e-02,  1.12961497e-01, -5.20971191e-01,\n",
       "         5.53326458e-01, -2.06672971e-01, -3.41177530e-01,\n",
       "        -2.38369551e-01,  8.90131885e-01, -3.19556185e-01,\n",
       "        -7.51218345e-01,  7.25255642e-01, -1.21775453e+00,\n",
       "         7.13168234e-02, -1.29985116e+00,  4.12780581e-02,\n",
       "        -8.98302183e-01, -1.48623995e+00, -5.04428698e-01,\n",
       "         2.36901631e-01, -2.30084924e-02,  2.44214287e+00,\n",
       "         1.30640223e-02, -8.20412073e-02, -4.15110215e-03,\n",
       "        -1.08020280e-02,  3.11001958e-02,  1.51817196e-01,\n",
       "         2.70212233e-02,  1.28389150e-02, -5.37199043e-02],\n",
       "       [-1.60243062e-01,  1.09114861e-01, -2.15867956e-01,\n",
       "         9.98941933e-02, -1.30607340e-01, -4.01323960e-02,\n",
       "        -1.83216312e-01,  6.81656496e-02, -7.00770932e-02,\n",
       "        -1.59189493e-01,  9.73487522e-02, -1.70066191e-01,\n",
       "         7.38285029e-03, -1.56278259e-01, -2.50463863e-03,\n",
       "        -1.30687996e-01, -2.27666223e-01, -8.42405222e-02,\n",
       "         2.81198997e-02,  1.18151244e-02,  1.30640223e-02,\n",
       "         2.22978070e+00, -2.11554027e-03,  6.33830356e-04,\n",
       "         5.26458189e-04,  1.30049119e-03,  6.02619566e-03,\n",
       "         6.90618206e-04, -8.64766718e-05, -7.10330959e-03],\n",
       "       [-4.03040697e-01,  2.08532641e-01, -2.54018879e-01,\n",
       "        -4.88445687e-02, -2.11526146e-01,  8.29734101e-02,\n",
       "        -3.24201150e-01, -3.06468030e-01, -2.29663861e-03,\n",
       "         8.26711079e-03, -1.46733774e-01,  2.30094830e-01,\n",
       "        -1.98218383e-02,  3.07800813e-01, -2.81653377e-02,\n",
       "         1.56841212e-01,  2.31311460e-01,  6.13392150e-02,\n",
       "        -5.69897775e-02,  4.13595391e-02, -8.20412073e-02,\n",
       "        -2.11554027e-03,  2.26632214e+00,  3.77310756e-03,\n",
       "         7.05291774e-03, -1.33702859e-02, -6.60612975e-02,\n",
       "        -1.26986224e-02, -7.05477396e-03,  1.11329777e-02],\n",
       "       [-1.22342573e-01,  7.52043203e-02, -1.29291561e-01,\n",
       "         3.93748051e-02, -8.53358454e-02, -8.03080970e-03,\n",
       "        -1.23086593e-01, -6.70977094e-03, -3.21166802e-02,\n",
       "        -7.12996456e-02,  2.61844173e-02, -4.89701743e-02,\n",
       "         9.17044808e-04, -3.31538266e-02, -4.60031612e-03,\n",
       "        -4.00870730e-02, -7.49869202e-02, -3.07276828e-02,\n",
       "         5.76813084e-03,  1.04518817e-02, -4.15110215e-03,\n",
       "         6.33830356e-04,  3.77310756e-03,  2.22856472e+00,\n",
       "         1.10621104e-03, -1.05290037e-03, -5.38372026e-03,\n",
       "        -1.24737977e-03, -9.06566195e-04, -1.85822530e-03],\n",
       "       [-1.63841192e-01,  9.77061056e-02, -1.59963460e-01,\n",
       "         3.90373238e-02, -1.08944193e-01, -2.36287441e-03,\n",
       "        -1.58603544e-01, -3.07930928e-02, -3.50728606e-02,\n",
       "        -7.68374304e-02,  1.71982033e-02, -3.55635016e-02,\n",
       "        -5.23678161e-04, -1.24189326e-02, -7.15847681e-03,\n",
       "        -3.15291658e-02, -6.37389842e-02, -2.86835037e-02,\n",
       "         1.89697658e-03,  1.45284014e-02, -1.08020280e-02,\n",
       "         5.26458189e-04,  7.05291774e-03,  1.10621104e-03,\n",
       "         2.22955578e+00, -2.16938527e-03, -1.09158706e-02,\n",
       "        -2.32919028e-03, -1.52605828e-03, -1.16530602e-03],\n",
       "       [ 8.41829781e-02, -3.55456486e-02,  1.79420236e-02,\n",
       "         4.66742830e-02,  2.99648574e-02, -3.96825070e-02,\n",
       "         5.11115545e-02,  1.22095331e-01, -2.06624683e-02,\n",
       "        -5.13928090e-02,  7.82391967e-02, -1.28010436e-01,\n",
       "         8.80602192e-03, -1.49470103e-01,  8.54032472e-03,\n",
       "        -9.17699349e-02, -1.46019693e-01, -4.60175257e-02,\n",
       "         2.74254039e-02, -1.00536994e-02,  3.11001958e-02,\n",
       "         1.30049119e-03, -1.33702859e-02, -1.05290037e-03,\n",
       "        -2.16938527e-03,  2.23262808e+00,  2.36690308e-02,\n",
       "         4.40678805e-03,  2.30449289e-03, -5.84973504e-03],\n",
       "       [ 4.55283232e-01, -2.01636669e-01,  1.38226223e-01,\n",
       "         2.09643220e-01,  1.78734259e-01, -1.88393540e-01,\n",
       "         2.95901909e-01,  5.92188700e-01, -8.69473131e-02,\n",
       "        -2.19685201e-01,  3.67311559e-01, -5.98528039e-01,\n",
       "         4.21520099e-02, -7.08453327e-01,  4.30709890e-02,\n",
       "        -4.27093611e-01, -6.75099226e-01, -2.09923059e-01,\n",
       "         1.30115737e-01, -5.27132059e-02,  1.51817196e-01,\n",
       "         6.02619566e-03, -6.60612975e-02, -5.38372026e-03,\n",
       "        -1.09158706e-02,  2.36690308e-02,  2.34424227e+00,\n",
       "         2.17750247e-02,  1.14885353e-02, -2.75026141e-02],\n",
       "       [ 1.33593726e-01, -6.92201622e-02,  8.46321232e-02,\n",
       "         1.57396206e-02,  7.02890810e-02, -2.72265840e-02,\n",
       "         1.07666358e-01,  1.00865665e-01,  1.02247280e-03,\n",
       "        -2.12661421e-03,  4.80490509e-02, -7.52804767e-02,\n",
       "         6.51258986e-03, -1.00972651e-01,  9.30297905e-03,\n",
       "        -5.12582160e-02, -7.54643757e-02, -1.99215124e-02,\n",
       "         1.86983152e-02, -1.36917413e-02,  2.70212233e-02,\n",
       "         6.90618206e-04, -1.26986224e-02, -1.24737977e-03,\n",
       "        -2.32919028e-03,  4.40678805e-03,  2.17750247e-02,\n",
       "         2.23200041e+00,  2.32814104e-03, -3.64664304e-03],\n",
       "       [ 1.20530604e-01, -6.90715354e-02,  1.05375545e-01,\n",
       "        -1.59400863e-02,  7.51646203e-02, -6.09266278e-03,\n",
       "         1.10860251e-01,  4.30024844e-02,  1.83944238e-02,\n",
       "         3.91254682e-02,  4.02142612e-03, -1.84801939e-03,\n",
       "         2.01991198e-03, -2.07064912e-02,  6.19719703e-03,\n",
       "         2.52039109e-03,  1.26589492e-02,  9.46765951e-03,\n",
       "         4.04256127e-03, -1.11836149e-02,  1.28389150e-02,\n",
       "        -8.64766718e-05, -7.05477396e-03, -9.06566195e-04,\n",
       "        -1.52605828e-03,  2.30449289e-03,  1.14885353e-02,\n",
       "         2.32814104e-03,  2.22922672e+00, -3.77499012e-04],\n",
       "       [ 5.22942338e-01, -3.62448532e-01,  7.32348346e-01,\n",
       "        -3.54953442e-01,  4.37514804e-01,  1.48714690e-01,\n",
       "         6.11096220e-01, -2.68566905e-01,  2.45476773e-01,\n",
       "         5.58934391e-01, -3.55473899e-01,  6.18472907e-01,\n",
       "        -2.77976804e-02,  5.77628470e-01,  6.06395406e-03,\n",
       "         4.73340370e-01,  8.20542654e-01,  3.01275441e-01,\n",
       "        -1.04090402e-01, -3.74345178e-02, -5.37199043e-02,\n",
       "        -7.10330959e-03,  1.11329777e-02, -1.85822530e-03,\n",
       "        -1.16530602e-03, -5.84973504e-03, -2.75026141e-02,\n",
       "        -3.64664304e-03, -3.77499012e-04,  2.25379216e+00]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reduced_pca.get_covariance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_reduced_tsne rows:  1566\n",
      "X_reduced_tsne rows:  2\n",
      "yresampled rows: 284807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('X_reduced_tsne rows: ', len(X_reduced_tsne))\n",
    "print('X_reduced_tsne rows: ', len(X_reduced_tsne[0]))\n",
    "#X_reduced_tsne has 1566 rows and 2 columns (for the x y plane coordinates)\n",
    "\n",
    "print('yresampled rows:', len(y))\n",
    "yresampled == 1\n",
    "#INTERESTING! you can apply true false on an array it seems!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test = np.array([np.random.randint(0,3) for x in range(0, len(yresampled))])\n",
    "\n",
    "# #ah you get it finally\n",
    "# #c can take in a list, or a single dimension array. smart enough to parse it correctly\n",
    "\n",
    "# arraytest = np.array([[1,2,3], [2,4,3]])\n",
    "\n",
    "# for x in arraytest:\n",
    "#     print(x[0])\n",
    "    \n",
    "# yresampled == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T06:05:27.257407Z",
     "start_time": "2020-03-02T06:05:26.855850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "f, (ax1) = plt.subplots(1, 1, figsize=(24,12))\n",
    "labels = ['No Fraud', 'Fraud']\n",
    "# f.suptitle('Clusters using Dimensionality Reduction', fontsize=14)\n",
    "\n",
    "\n",
    "blue_patch = mpatches.Patch(color='#0A0AFF', label='No Fraud')\n",
    "red_patch = mpatches.Patch(color='#AF0000', label='Fraud')\n",
    "\n",
    "\n",
    "# t-SNE scatter plot\n",
    "ax1.scatter(X_reduced_tsne[:,0], X_reduced_tsne[:,1], c=(yresampled == 0), cmap='coolwarm', label='No Fraud', linewidths=2)\n",
    "ax1.scatter(X_reduced_tsne[:,0], X_reduced_tsne[:,1], c=(yresampled == 1), cmap='coolwarm', label='Fraud', linewidths=2)\n",
    "ax1.set_title('t-SNE', fontsize=14)\n",
    "\n",
    "ax1.grid(True)\n",
    "\n",
    "ax1.legend(handles=[blue_patch, red_patch], fontsize = 18)\n",
    "\n",
    "\n",
    "# # PCA scatter plot\n",
    "# ax2.scatter(X_reduced_pca[:,0], X_reduced_pca[:,1], c=(yresampled == 0), cmap='coolwarm', label='No Fraud', linewidths=2)\n",
    "# ax2.scatter(X_reduced_pca[:,0], X_reduced_pca[:,1], c=(yresampled == 1), cmap='coolwarm', label='Fraud', linewidths=2)\n",
    "# ax2.set_title('PCA', fontsize=14)\n",
    "\n",
    "# ax2.grid(True)\n",
    "\n",
    "# ax2.legend(handles=[blue_patch, red_patch])\n",
    "\n",
    "# # TruncatedSVD scatter plot\n",
    "# ax3.scatter(X_reduced_svd[:,0], X_reduced_svd[:,1], c=(yresampled == 0), cmap='coolwarm', label='No Fraud', linewidths=2)\n",
    "# ax3.scatter(X_reduced_svd[:,0], X_reduced_svd[:,1], c=(yresampled == 1), cmap='coolwarm', label='Fraud', linewidths=2)\n",
    "# ax3.set_title('Truncated SVD', fontsize=14)\n",
    "\n",
    "# ax3.grid(True)\n",
    "\n",
    "# ax3.legend(handles=[blue_patch, red_patch])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#really don't get the syntax.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resampled variables columns= 30\n",
      "original variables columns = 30\n"
     ]
    }
   ],
   "source": [
    "#test various models\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "Classifiers = {'logisticregression': LogisticRegression(),\n",
    "             'randomforest': RandomForestClassifier(),\n",
    "             'svectorclassifier': SVC(),\n",
    "              'KNN': KNeighborsClassifier(),\n",
    "             }\n",
    "\n",
    "# .values converts whatever dataframe into an array!\n",
    "print('resampled variables columns=', len(Xresampled[0]))\n",
    "print('original variables columns =', len(X.values[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xtzie/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/xtzie/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/xtzie/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/xtzie/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/xtzie/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/xtzie/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/xtzie/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/xtzie/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/xtzie/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/xtzie/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/xtzie/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/xtzie/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/xtzie/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/xtzie/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/xtzie/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'logisticregression': [0.861, 0.936, 0.897, 0.904],\n",
       " 'randomforest': [0.884, 0.972, 0.926, 0.933],\n",
       " 'svectorclassifier': [0.918, 0.937, 0.928, 0.929],\n",
       " 'KNN': [0.927, 0.913, 0.92, 0.92]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train with Xresampled\n",
    "#then do cross validation\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "#import your measurables\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "CVscores_unoptimized = {}\n",
    "CVscores_columns = ['precision', 'recall', 'f1-score', 'AUC ROC']\n",
    "\n",
    "for key, classifier in Classifiers.items():\n",
    "    modelpredictions = cross_val_predict(classifier, Xresampled, yresampled, cv = 5)\n",
    "    a = round(precision_score(modelpredictions, yresampled), 3)\n",
    "    b = round(recall_score(modelpredictions, yresampled), 3)\n",
    "    c = round(f1_score(modelpredictions, yresampled), 3)\n",
    "    d = round(roc_auc_score(modelpredictions, yresampled), 3)\n",
    "    toupdate= {key: [a, b, c, d]}\n",
    "    CVscores_unoptimized.update(toupdate)\n",
    "\n",
    "CVscores_unoptimized\n",
    "#put results to a csv that can be easily manipulated into ppt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression': [0.861, 0.936, 0.897, 0.904],\n",
       " 'randomforest': [0.884, 0.972, 0.926, 0.933],\n",
       " 'svectorclassifier': [0.918, 0.937, 0.928, 0.929],\n",
       " 'KNN': [0.927, 0.913, 0.92, 0.92],\n",
       " 'xgboost': [0.999, 0.994, 0.996, 0.996]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=Xresampled,label=yresampled)\n",
    "xgclassifier = xgb.XGBClassifier()\n",
    "model = xgclassifier.fit(Xresampled,yresampled)\n",
    "\n",
    "modelpredictions = model.predict(Xresampled)\n",
    "a = round(precision_score(modelpredictions, yresampled), 3)\n",
    "b = round(recall_score(modelpredictions, yresampled), 3)\n",
    "c = round(f1_score(modelpredictions, yresampled), 3)\n",
    "d = round(roc_auc_score(modelpredictions, yresampled), 3)\n",
    "toupdate = {'xgboost': [a, b, c, d]}\n",
    "CVscores_unoptimized.update(toupdate)\n",
    "CVscores_unoptimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best parameters from gridsearch\n",
    "log_reg_bestparams = LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "rtree_bestparams = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "                       max_depth=7, max_features=3, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=3, min_samples_split=10,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=400,\n",
    "                       n_jobs=None, oob_score=False, random_state=None,\n",
    "                       verbose=0, warm_start=False)\n",
    "svc_bestparams = SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
    "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
    "    shrinking=True, tol=0.001, verbose=False)\n",
    "KNN_bestparams = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "                     metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
    "                     weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xtzie/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/xtzie/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/xtzie/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/xtzie/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/xtzie/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/xtzie/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/xtzie/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/xtzie/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/xtzie/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/xtzie/anaconda3/envs/metis/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'logisticregression': [0.861, 0.936, 0.897, 0.904],\n",
       " 'randomforest': [0.829, 0.973, 0.895, 0.912],\n",
       " 'svectorclassifier': [0.918, 0.937, 0.928, 0.929],\n",
       " 'KNN': [0.928, 0.955, 0.942, 0.943]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing with optimized parameters\n",
    "optimized_classifiers = {'logisticregression': log_reg_bestparams,\n",
    "             'randomforest': rtree_bestparams,\n",
    "             'svectorclassifier': svc_bestparams,\n",
    "              'KNN': KNN_bestparams,\n",
    "             }\n",
    "\n",
    "CVscores_optimized = {}\n",
    "\n",
    "for key, classifier in optimized_classifiers.items():\n",
    "    modelpredictions = cross_val_predict(classifier, Xresampled, yresampled, cv = 5)\n",
    "    a = round(precision_score(modelpredictions, yresampled), 3)\n",
    "    b = round(recall_score(modelpredictions, yresampled), 3)\n",
    "    c = round(f1_score(modelpredictions, yresampled), 3)\n",
    "    d = round(roc_auc_score(modelpredictions, yresampled), 3)\n",
    "    toupdate= {key: [a, b, c, d]}\n",
    "    CVscores_optimized.update(toupdate)\n",
    "\n",
    "CVscores_optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logisticregression': [0.861, 0.936, 0.897, 0.904], 'randomforest': [0.884, 0.972, 0.926, 0.933], 'svectorclassifier': [0.918, 0.937, 0.928, 0.929], 'KNN': [0.927, 0.913, 0.92, 0.92], 'xgboost': [0.999, 0.994, 0.996, 0.996]}\n"
     ]
    }
   ],
   "source": [
    "#let's compare optimized and unoptimized\n",
    "\n",
    "print(CVscores_unoptimized)\n",
    "# print(CVscores_optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for overfitting with the very first/original testing set\n",
    "#WWWWWWWWWWWWWW\n",
    "#should you test on resampled testing data (i.e random undersample it)\n",
    "#or the plain testing data\n",
    "Xtestingresampled, ytestingresampled = rus.fit_resample(Xtesting, ytesting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa650b13e90>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=Xresampled,label=yresampled)\n",
    "xgclassifier = xgb.XGBClassifier()\n",
    "model = xgclassifier.fit(Xresampled,yresampled)\n",
    "\n",
    "threshold = 0.8\n",
    "\n",
    "fraudprobarray = model.predict_proba(Xtesting.values)\n",
    "fraudprob = fraudprobarray[:, 1]\n",
    "thresholdvals = np.array([1 if x > threshold else 0 for x in fraudprob])\n",
    "\n",
    "modelpredictions = model.predict_proba(Xtesting.values)\n",
    "\n",
    "test = confusion_matrix(ytesting, thresholdvals)\n",
    "\n",
    "#sum of row0 = actual non frauds len(ytesting[ytesting == 0])\n",
    "#sum of row1 = actual frauds len(ytesting[ytesting == 1])\n",
    "\n",
    "sns.heatmap(test, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC ROC curve here\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finishing touches - UMAP distribution\n",
    "#fine tune hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ypredicted_testing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-5a0b77d52b24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#easypeasy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#can use this as the quick ditsy metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mf1fortesting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytesting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mypredicted_testing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mroctesting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytesting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mypredicted_testing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ypredicted_testing' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#you don't have to undersample your test set.\n",
    "#but look at what the precision and recall is\n",
    "\n",
    "f1 = f1_score\n",
    "#easypeasy\n",
    "#can use this as the quick ditsy metric\n",
    "f1fortesting = f1_score(ytesting, ypredicted_testing)\n",
    "roctesting = roc_auc_score(ytesting, ypredicted_testing)\n",
    "\n",
    "#inputs, and outputs\n",
    "#next you need to understand\n",
    "\n",
    "confusionframe = pd.DataFrame(confusion_matrix(ytesting, ypredicted_testing))\n",
    "confusionframe.columns = ['Non Fraud', 'Fraud']\n",
    "confusionframe\n",
    "\n",
    "#WWWWWWWWWWWWWwWWWWWWW\n",
    "#what is a good score to use when shortlisting models?\n",
    "#F1, ROC, \n",
    "#how does cross validation return the predicted scores?\n",
    "roctesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_curve(ytesting, ypredicted_testing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
